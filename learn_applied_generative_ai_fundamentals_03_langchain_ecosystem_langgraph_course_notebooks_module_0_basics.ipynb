{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaj/6KIu2Nxa/KqtxhA5RM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAVEED261/MY-AI-ASSISTANT/blob/main/learn_applied_generative_ai_fundamentals_03_langchain_ecosystem_langgraph_course_notebooks_module_0_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LangChain Academy**\n",
        "LangChain Academy mein khush aamdeed!\n",
        "\n",
        "# Tanazur (Context)\n",
        "LangChain mein hamara maqsad yeh hai ke LLM (Large Language Model) applications banana asaan banayein. LLM applications ka ek type jo tum bana sakte ho wo hai agent. Agents ka banana bohot exciting hai kyunke yeh bohot se woh tasks automate kar sakte hain jo pehle mumkin nahi the.\n",
        "\n",
        "Amal mein lekin, aise systems banana jo reliably yeh tasks poora karein, kaafi mushkil hota hai. Jab humne apne users ke saath agents ko production mein deploy karna shuru kiya, to humein yeh samajh aya ke zyada control zaroori hai. Ho sakta hai ke tumhein ek agent chahiye jo pehle kisi specific tool ko use kare ya apne state ke mutabiq alag prompts ka istemal kare.\n",
        "\n",
        "Is masle ka hal nikaalne ke liye, humne LangGraph banaya hai — yeh ek framework hai jo agent aur multi-agent applications banane ke liye hai. LangChain package se alag, LangGraph ka core design philosophy yeh hai ke developers ko agent workflows mein zyada precision aur control dene mein madad mile, jo ke real-world systems ki complexity ke liye suitable ho.\n",
        "\n",
        "# ***Course ka Dhanchaa (Course Structure)***\n",
        "Yeh course mukhtalif modules ki soorat mein bana hua hai, aur har module LangGraph ke ek khaas theme par focus karta hai. Tumhein har module ke liye ek folder nazar aayega jo kuch notebooks par mushtamil hoga. Har notebook ke saath ek video bhi hoga jo concepts ko explain karega, lekin notebooks khud bhi stand-alone hain, yani tum inhe bina videos ke bhi parh sakte ho. Har module folder mein ek studio folder bhi hai, jo LangGraph Studio mein load hone wale graphs ka set rakhta hai. LangGraph Studio hamara IDE hai jo LangGraph applications banane mein madad karta hai.\n",
        "\n",
        "# Setup\n",
        "Shuru karne se pehle, README mein diye gaye instructions follow karo taake environment setup aur dependencies install ki ja sakein.\n",
        "\n",
        "# Chat Models\n",
        "Is course mein hum Chat Models ka istemal karenge, jo kuch messages ka sequence input mein lete hain aur chat messages ko output mein dete hain. LangChain koi bhi Chat Model host nahi karta, balke yeh third party integrations par inhesar karta hai. LangChain mein third-party chat model integrations ka aik list hai! Default ke tor par, course mein ChatOpenAI ka istemal hoga kyunke yeh popular aur performant hai. Jaise ke bataya gaya hai, please ensure ke tumhare paas OPENAI_API_KEY maujood hai.\n",
        "\n",
        "Chalo check karte hain ke tumhara OPENAI_API_KEY set hai ya nahi, aur agar nahi hai to tumhein enter karne ke liye kaha jayega."
      ],
      "metadata": {
        "id": "pKmmu0oY2jFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langchain_google_genai langchain_core tavily-python langchain_community\n",
        "\n"
      ],
      "metadata": {
        "id": "hzwUxLya31Ss"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeh packages alag alag kaam ke liye install kiye gaye hain:\n",
        "\n",
        "# langchain_google_genai:\n",
        "Google Generative AI ko LangChain ke sath integrate karne ke liye.\n",
        "# langchain_core:\n",
        "LangChain ka core functionality core library use k lya hota  ta k hum ai or human msg la skain\n",
        "# langchain_community:\n",
        "Community-contributed tools aur integrations ko access karne ke liye.\n",
        "# tavily-python:\n",
        " Tavily search engine ko LLM applications mein use karne ke liye, jo optimized search results deta hai. MEANS WEB SEARCH\n",
        "# NOTE :\n",
        " TAVILY_PYTHON LANGCHAIN COMMUNITY KA PACKAGE HA ISLYA LANGCHAIN COMMUNITY OR YA DONO SATH INSTALL KRNA ZARORI HA\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4uo820IcLq8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "gemini_api_key = userdata.get('my_stenographer_key')\n",
        "TAVILY_API_KEY = userdata.get(\"TAVILY_API_KEY\")\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults # Import the necessary class\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    max_retries=2,\n",
        "    api_key=gemini_api_key\n",
        ")\n",
        "tool = TavilySearchResults(max_results=4)\n",
        "tools = [tool]"
      ],
      "metadata": {
        "id": "4ZpZx6jY7GnM"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"hello fatima and uamima\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytyIWYRb-_RF",
        "outputId": "68d0ace5-1673-46ae-d66c-d2592c8096e0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hello! \\n\\nIt seems you're trying to address Fatima and Uamima. \\n\\nIs there anything specific you'd like to say to them? I'm happy to help you craft a message. Just let me know! \\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-da2289c0-2b1c-4627-b96a-19bd37605e66-0', usage_metadata={'input_tokens': 8, 'output_tokens': 49, 'total_tokens': 57, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool.invoke(\"what is current weather in karachi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew-_uvVsHIen",
        "outputId": "057ead42-233d-4700-f6db-06e8563db88f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'url': 'https://www.weatherapi.com/',\n",
              "  'content': \"{'location': {'name': 'Karachi', 'region': 'Sindh', 'country': 'Pakistan', 'lat': 24.8667, 'lon': 67.05, 'tz_id': 'Asia/Karachi', 'localtime_epoch': 1731142128, 'localtime': '2024-11-09 13:48'}, 'current': {'last_updated_epoch': 1731141900, 'last_updated': '2024-11-09 13:45', 'temp_c': 30.1, 'temp_f': 86.2, 'is_day': 1, 'condition': {'text': 'Sunny', 'icon': '//cdn.weatherapi.com/weather/64x64/day/113.png', 'code': 1000}, 'wind_mph': 11.2, 'wind_kph': 18.0, 'wind_degree': 249, 'wind_dir': 'WSW', 'pressure_mb': 1012.0, 'pressure_in': 29.9, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 60, 'cloud': 0, 'feelslike_c': 33.3, 'feelslike_f': 91.9, 'windchill_c': 30.1, 'windchill_f': 86.2, 'heatindex_c': 33.3, 'heatindex_f': 91.9, 'dewpoint_c': 21.5, 'dewpoint_f': 70.6, 'vis_km': 10.0, 'vis_miles': 6.0, 'uv': 6.0, 'gust_mph': 12.9, 'gust_kph': 20.7}}\"},\n",
              " {'url': 'https://www.ventusky.com/26.700;67.440',\n",
              "  'content': \"Location - Weather Forecast Maps | Ventusky Ventusky: Weather Forecast Maps A new global model from the South Korea Meteorological Institute   Lat.:\\xa026°41'N\\xa0/\\xa0Lon.:\\xa067°26'E\\xa0/\\xa0Altitude:\\xa0174 ft Timezone:\\xa0Asia/Karachi (UTC+5) /\\xa0Current time:\\xa001:48 PM 11/09/2024 02 PM 03 PM 04 PM 05 PM 06 PM 07 PM 08 PM 09 PM 10 PM 11 PM 12 PM tomorrow 01 PM tomorrow 02 PM tomorrow 02 PM 05 PM 08 PM 11 PM New snow Air quality (AQI) Values over 300 represents hazardous air quality, between 200-300 very unhealthy, 150-200 unhealthy, 100-150 unhealthy for sensitive groups and below 100 or rather below 50 the air quality is good. Weather report from station Weather report from station;Distance Altitude: Altitude:\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeh aik useful guide hai jo tumhein chat models ke mukhtalif istemalat ke bare mein bataata hai, lekin kuch highlights niche explain kiye gaye hain. Agar tumne README mein diye gaye instructions ke mutabiq pip install -r requirements.txt run kiya hai, to tumne langchain-openai package install kar liya hai. Is se tum apna ChatOpenAI model object instantiate kar sakte ho. Agar tum API pe pehli dafa signup kar rahe ho, to tumhein free credits milne chahiye jo tum kisi bhi model pe istemal kar sakte ho. Mukhtalif models ki pricing yahan dekhi ja sakti hai. Yeh notebooks default tor pe gpt-4 par set hain kyunki yeh quality, price, aur speed ka acha balance deta hai, lekin tum lower priced gpt-3.5 series models bhi choose kar sakte ho.\n",
        "\n",
        "Chat models ke saath kuch standard parameters set kiye ja sakte hain. Do common parameters yeh hain:\n",
        "\n",
        "model: yeh model ka naam hai jo tum istemal karna chahte ho.\n",
        "temperature: sampling temperature.\n",
        "Temperature model ke output mein randomness ya creativity ko control karta hai. Low temperature (qareeb 0 ke) deterministic aur focused outputs dete hain, jo ke un tasks ke liye acha hai jahan accuracy ya factual responses chahiye hoon. High temperature (qareeb 1 ke) creative tasks ya varied responses generate karne mein madadgar hota hai.\n",
        "\n",
        "Example: Agar tumhein ek specific jawab chahiye, to temperature ko low rakho (jaise 0.2-0.3), aur agar tumhein creative aur different options chahiye to temperature ko high (jaise 0.8-0.9) set kar sakte ho.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JLBq9X4o4Wwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LangChain mein chat models ke kuch default methods hote hain jo kaam ko asaan banate hain. Zyadatar hum ye methods use karenge:\n",
        "\n",
        "stream: Is method ka kaam yeh hai ke response ko chunks mein stream kare, yani jawab ko chhoti chhoti qisam mein user tak pohchaye.\n",
        "invoke: Iska kaam hai ke kisi input par chain ko call kare, yani jo input diya gaya ho us par kaam shuru kare.\n",
        "Jaise ke pehle mention kiya gaya hai, chat models messages ko input ke tor par lete hain. Messages mein do important properties hoti hain:\n",
        "\n",
        "role: yeh batata hai ke message kis ki taraf se aaya hai (jaise user ya system).\n",
        "content: yeh message ka asal mazmoon ya text hai.\n",
        "Aage ja kar hum is par aur tafseel mein baat karenge, lekin yahan sirf basics ko samajhne ke liye itna hi kaafi hai.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3lyP6wla4lgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# Create a message option in normal forms\n",
        "msg : HumanMessage(content=\"assalamualykum\", name=\"fatima and umaima\")\n",
        "\n",
        "# messages = HumanMessage(content=\"assalamualykum\", name=\"fatima and umaima\")\n",
        "\n",
        "# conversation always in list form\n",
        "messages = [msg]\n",
        "\n",
        "# messages = [ HumanMessage(content=\"assalamualykum\", name=\"fatima and umaima\")]\n",
        "\n",
        "# Message list\n",
        "\n",
        "# option in structural form\n",
        "\n",
        "# messages = [\n",
        "#     HumanMessage(content=\"assalamualykum\", name=\"fatima and umaima\"),\n",
        "#     AIMessage(content=\"Wa alaikum assalam wa rahmatullahi wa barakatuh,  \\n\", name=\"AI assistant\"),\n",
        "#     HumanMessage(content=\"What is LangChain?\", name=\"fatima and umaima\")\n",
        "#     ]\n",
        "\n",
        "# Invoke the model with a list of messages\n",
        "llm.invoke(messages)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0iJqrcI4oNL",
        "outputId": "32fb46e0-f904-4f5c-c1f0-5da1054e457a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Wa alaikum assalam wa rahmatullahi wa barakatuh! \\n\\nHow can I help you today? \\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-8ead173c-c5fd-4759-9fcd-b6b405a4d6d4-0', usage_metadata={'input_tokens': 6, 'output_tokens': 25, 'total_tokens': 31, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get an AIMessage response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a HumanMessage and then passed to the underlying model."
      ],
      "metadata": {
        "id": "muOG2sOL4trs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat models ka interface har model mein consistent hota hai, yani yeh sab models ke liye ek hi tarike se kaam karta hai. Aksar models ko notebook ke shuru mein ek dafa initialize kiya jata hai. Iska faida yeh hai ke agar tum kisi aur provider ka model use karna chaho, to tum asaani se models ko switch kar sakte ho bina niche wale code ko change kiye.\n",
        "\n",
        "# ***Search Tools***\n",
        " README mein tumhe Tavily ka zikar bhi milega, jo ek search engine hai jo LLMs aur RAG (Retrieval-Augmented Generation) ke liye optimize kiya gaya hai. Yeh efficient, quick aur persistent search results dene ke liye bana hai. Signup karna asaan hai aur yeh free tier bhi offer karta hai jo kaafi faidemand hai. Kuch lessons (Module 4 mein) default tor pe Tavily use karenge, lekin agar tum chaho to apna code modify karke doosre search tools bhi istemal kar sakte ho.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "olItjabk47vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_docs = []"
      ],
      "metadata": {
        "id": "0qpD9-HcM13N"
      },
      "execution_count": 99,
      "outputs": []
    }
  ]
}