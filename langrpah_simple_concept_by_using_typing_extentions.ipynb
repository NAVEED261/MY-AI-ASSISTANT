{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMkQ4DzoTVonvYzrM+FDoRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAVEED261/MY-AI-ASSISTANT/blob/main/langrpah_simple_concept_by_using_typing_extentions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9l80KAeRxOU",
        "outputId": "0094217c-eed2-4c18-fdab-d37a51359b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "# Install typing_extensions for TypedDict support\n",
        "!pip install typing-extensions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "\n",
        "# Define the state using TypedDict for better structure\n",
        "class LearningState(TypedDict):\n",
        "    prompt: str\n",
        "    agent_output: str\n",
        "    final_output: str\n",
        "\n",
        "# Define a basic class structure for nodes\n",
        "class Node:\n",
        "    def __init__(self, name: str):\n",
        "        self.name = name\n",
        "        self.next_node = None\n",
        "\n",
        "    def set_next(self, next_node):\n",
        "        self.next_node = next_node\n",
        "\n",
        "    def execute(self, state: LearningState):\n",
        "        print(f\"{self.name}: Executing...\")\n",
        "        return state\n",
        "\n",
        "# Define specific nodes for the workflow\n",
        "class StartNode(Node):\n",
        "    def execute(self, state: LearningState):\n",
        "        state[\"prompt\"] = input(\"Enter your prompt: \")\n",
        "        print(f\"Start Node: Received prompt '{state['prompt']}'\")\n",
        "        return state\n",
        "\n",
        "class AgentNode(Node):\n",
        "    def execute(self, state: LearningState):\n",
        "        print(f\"Agent Node: Processing prompt '{state['prompt']}'\")\n",
        "        state[\"agent_output\"] = f\"Processed: {state['prompt']}\"\n",
        "        return state\n",
        "\n",
        "class ConditionalEdge(Node):\n",
        "    def __init__(self, name: str, condition, true_node: Node, false_node: Node):\n",
        "        super().__init__(name)\n",
        "        self.condition = condition\n",
        "        self.true_node = true_node\n",
        "        self.false_node = false_node\n",
        "\n",
        "    def execute(self, state: LearningState):\n",
        "        print(f\"Conditional Edge: Checking condition...\")\n",
        "        if self.condition(state):\n",
        "            print(\"Condition met, going to LLM Node.\")\n",
        "            return self.true_node.execute(state)\n",
        "        else:\n",
        "            print(\"Condition not met, going to Tool Node.\")\n",
        "            return self.false_node.execute(state)\n",
        "\n",
        "class LLMNode(Node):\n",
        "    def execute(self, state: LearningState):\n",
        "        print(f\"LLM Node: Refining response from agent output '{state['agent_output']}'\")\n",
        "        state[\"final_output\"] = f\"LLM Refined: {state['agent_output']}\"\n",
        "        return state\n",
        "\n",
        "class ToolNode(Node):\n",
        "    def execute(self, state: LearningState):\n",
        "        print(f\"Tool Node: Processing response with external tools for '{state['agent_output']}'\")\n",
        "        state[\"final_output\"] = f\"Tool Processed: {state['agent_output']}\"\n",
        "        return state\n",
        "\n",
        "class EndNode(Node):\n",
        "    def execute(self, state: LearningState):\n",
        "        print(f\"End Node: Final output is '{state['final_output']}'\")\n",
        "        return state\n",
        "\n",
        "# Create workflow with nodes and edges\n",
        "def create_workflow():\n",
        "    # Create nodes\n",
        "    start_node = StartNode(\"Start\")\n",
        "    agent_node = AgentNode(\"Agent\")\n",
        "    llm_node = LLMNode(\"LLM\")\n",
        "    tool_node = ToolNode(\"Tool\")\n",
        "    end_node = EndNode(\"End\")\n",
        "\n",
        "    # Define condition function for ConditionalEdge\n",
        "    def condition(state: LearningState) -> bool:\n",
        "        # Condition for deciding whether to call LLM or Tool\n",
        "        return \"AI\" in state[\"prompt\"]\n",
        "\n",
        "    # Conditional edge to decide between LLM or Tool\n",
        "    conditional_edge = ConditionalEdge(\"Conditional Edge\", condition, llm_node, tool_node)\n",
        "\n",
        "    # Link nodes\n",
        "    start_node.set_next(agent_node)\n",
        "    agent_node.set_next(conditional_edge)\n",
        "    llm_node.set_next(end_node)\n",
        "    tool_node.set_next(end_node)\n",
        "\n",
        "    return start_node\n",
        "\n",
        "# Run the workflow\n",
        "def run_workflow():\n",
        "    start_node = create_workflow()\n",
        "    state = LearningState(prompt=\"\", agent_output=\"\", final_output=\"\")\n",
        "    current_node = start_node\n",
        "\n",
        "    while current_node:\n",
        "        state = current_node.execute(state)\n",
        "        current_node = current_node.next_node\n",
        "\n",
        "# Start the process\n",
        "run_workflow()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SEJSumXS4A8",
        "outputId": "195e19da-145a-4008-8a52-5e529ce2b82c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your prompt:  AI in healthcare\n",
            "Start Node: Received prompt ' AI in healthcare'\n",
            "Agent Node: Processing prompt ' AI in healthcare'\n",
            "Conditional Edge: Checking condition...\n",
            "Condition met, going to LLM Node.\n",
            "LLM Node: Refining response from agent output 'Processed:  AI in healthcare'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Step-by-Step Explanation:***\n",
        "Start Node:\n",
        "\n",
        "Yahan se process start hota hai, aur user se prompt liya jata hai.\n",
        "Example: \"AI in healthcare.\"\n",
        "Agent Node:\n",
        "\n",
        "Agent prompt ko process karta hai aur output generate karta hai.\n",
        "Example: \"Processed: AI in healthcare.\"\n",
        "Conditional Edge:\n",
        "\n",
        "Yahan agent check karta hai ke prompt mein \"AI\" hai ya nahi. Agar \"AI\" hai to LLM Node call hoti hai, warna Tool Node.\n",
        "Example: Agar \"AI\" shamil hai, to LLM ko call karega.\n",
        "LLM Node (if condition is true):\n",
        "\n",
        "Agent ka output refine hota hai using LLM.\n",
        "Example: \"LLM Refined: Processed: AI in healthcare.\"\n",
        "Tool Node (if condition is false):\n",
        "\n",
        "Agar condition false hai, to tool use karke output process kiya jata hai.\n",
        "Example: \"Tool Processed: Processed: AI in healthcare.\"\n",
        "End Node:\n",
        "\n",
        "Final output generate hota hai aur user ko dikhaya jata hai.\n",
        "Example: \"LLM Refined: Processed: AI in healthcare.\"\n",
        "Summary of Key Concepts:\n",
        "Start: Yahan prompt diya jata hai aur workflow shuru hota hai.\n",
        "Agent Node: Prompt ko process karke intermediate result banata hai.\n",
        "Conditional Edge: Yahan decision hota hai ke LLM ko call karna hai ya tool ko.\n",
        "LLM/Tool Nodes: Agent ka output refine ya process hota hai.\n",
        "End: Final output user ko dikhaya jata hai.\n",
        "Sample Output:\n",
        "sql\n",
        "Copy code\n",
        "Enter your prompt: AI in healthcare\n",
        "Start Node: Received prompt 'AI in healthcare'\n",
        "Agent Node: Processing prompt 'AI in healthcare'\n",
        "Conditional Edge: Checking condition...\n",
        "Condition met, going to LLM Node.\n",
        "LLM Node: Refining response from agent output 'Processed: AI in healthcare'\n",
        "End Node: Final output is 'LLM Refined: Processed: AI in healthcare'\n",
        "# Kya Install Hoga:\n",
        "typing-extensions package ko install karna hoga for TypedDict."
      ],
      "metadata": {
        "id": "flu3lLaGTrf1"
      }
    }
  ]
}