{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9z//JhfcVkhSxOS25Yb1F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAVEED261/MY-AI-ASSISTANT/blob/main/multiple_agent_in_langraph_with_llm_practice_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install LangGraph, LangChain, and Google Generative AI LLM (if not installed)\n",
        "!pip install -U langgraph\n",
        "!pip install -U langchain\n",
        "!pip install -U langchain-google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgsJZgsssWlY",
        "outputId": "38968b9c-1e4e-4776-d0bb-dad66fbe8177"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.39)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.2.39 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.12)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (0.1.136)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.27.2)\n",
            "Requirement already satisfied: httpx-sse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.4.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.39->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.39->langgraph) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.2.2)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.12)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.136)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.15.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.9)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: langchain-text-splitters, langchain\n",
            "Successfully installed langchain-0.3.4 langchain-text-splitters-0.3.0\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.12)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.1.136)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10.9)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.2.2)\n",
            "Downloading langchain_google_genai-2.0.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-google-genai\n",
            "Successfully installed langchain-google-genai-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import Necessary Tools\n",
        "from langgraph.graph import StateGraph, START, END  # LangGraph imports\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "from typing_extensions import TypedDict  # To define the schema\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI  # Import for Google LLM\n",
        "from google.colab import userdata  # For fetching API key\n",
        "\n",
        "# Step 3: Define the State (Schema) for LangGraph\n",
        "class FirstLLMAgentCall(TypedDict):\n",
        "    prompt: str\n",
        "    output: str\n",
        "\n",
        "# Step 4: Fetch Google API key (replace 'my_stenographer_key' with your API key name)\n",
        "google_api_key = userdata.get('my_stenographer_key')\n",
        "\n",
        "# Step 5: Initialize Google LLM (Gemini) using LangChain\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # This specifies the version of the LLM\n",
        "    api_key=google_api_key  # Use the fetched API key\n",
        ")\n",
        "\n",
        "# Step 6: Define the Nodes\n",
        "# Node 1 will send the prompt to LLM and get a response\n",
        "def node_1(state: FirstLLMAgentCall):\n",
        "    print(\"---Node 1---\", state)\n",
        "    prompt = state[\"prompt\"]\n",
        "    ai_msg: AIMessage = llm.invoke(prompt)\n",
        "    return {\"output\": ai_msg.content}\n",
        "\n",
        "# Step 7: Build the Graph\n",
        "builder: StateGraph = StateGraph(state_schema=FirstLLMAgentCall)\n",
        "builder.add_node(\"node_1\", node_1)\n",
        "\n",
        "# Step 8: Add edges between the nodes\n",
        "builder.add_edge(START, \"node_1\")\n",
        "builder.add_edge(\"node_1\", END)\n",
        "\n",
        "# Step 9: Compile the Graph\n",
        "graph: CompiledStateGraph = builder.compile()\n",
        "\n",
        "# Step 10: Execute the Graph with an Initial Prompt\n",
        "result = graph.invoke({\"prompt\": \"Motivate me to learn LangGraph\"})  # Send initial prompt\n",
        "print(\"Final Output from LLM:\")\n",
        "print(result[\"output\"])  # Display the final output returned by LLM\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DDVUg5zsZbX",
        "outputId": "337f1f07-5cac-46c8-c7d1-f944c11571a3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Node 1--- {'prompt': 'Motivate me to learn LangGraph'}\n",
            "Final Output from LLM:\n",
            "## Why Learn LangGraph? 🚀\n",
            "\n",
            "LangGraph is a powerful tool for anyone interested in **understanding and manipulating language data**. It offers a unique blend of graph databases and natural language processing (NLP) capabilities, making it a versatile tool for various applications. \n",
            "\n",
            "**Here's why you should consider learning LangGraph:**\n",
            "\n",
            "**1. Unleash the Power of Graph Databases for NLP:**\n",
            "\n",
            "* **Intuitive Representation:** LangGraph allows you to represent complex relationships between words, concepts, and entities in a natural and intuitive way, unlike traditional NLP approaches that rely on linear text structures.\n",
            "* **Efficient Querying:**  Leverage graph databases' advanced querying capabilities to quickly and efficiently retrieve relevant information from your language data.\n",
            "* **Knowledge Discovery:**  Uncover hidden connections and insights within your data by analyzing the relationships between entities and concepts.\n",
            "\n",
            "**2. A Wide Range of Applications:**\n",
            "\n",
            "* **Semantic Search:** Build intelligent search engines that understand user intent and retrieve the most relevant results.\n",
            "* **Text Summarization:**  Generate concise and informative summaries of lengthy documents by identifying key entities and relationships.\n",
            "* **Sentiment Analysis:**  Analyze the sentiment of text by understanding the relationships between words and their emotional connotations.\n",
            "* **Knowledge Graph Construction:**  Build knowledge graphs from unstructured data, providing a structured representation of knowledge for various applications.\n",
            "* **Natural Language Understanding:**  Develop better language models and AI systems by leveraging the semantic knowledge captured in LangGraph.\n",
            "\n",
            "**3. A Growing Community and Resources:**\n",
            "\n",
            "* **Open Source:** LangGraph is an open-source project, fostering collaboration and innovation within the community.\n",
            "* **Active Development:** The project is actively developed and maintained, ensuring regular updates and improvements.\n",
            "* **Comprehensive Documentation:**  LangGraph offers extensive documentation and tutorials to help you get started and master its functionalities.\n",
            "\n",
            "**4. Future-Proof Your Skills:**\n",
            "\n",
            "* **Emerging Technology:** Graph databases and NLP are rapidly evolving fields with immense potential. Learning LangGraph will provide you with a valuable skillset for future opportunities.\n",
            "* **Cross-Disciplinary Applications:**  LangGraph's unique approach makes it applicable to various fields, including data science, AI, linguistics, and information retrieval.\n",
            "\n",
            "**Learning LangGraph can unlock new possibilities in your career and research. It offers a powerful and intuitive way to work with language data, opening doors to exciting opportunities in the world of NLP and beyond.**\n",
            "\n",
            "**Ready to embark on your LangGraph journey?  Let's dive in!** 🚀\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Step-by-Step Breakdown:***\n",
        "Step 1: Install Libraries:\n",
        "\n",
        "Install LangGraph, LangChain, and Google LLM (Gemini) libraries using pip.\n",
        "Step 2: Import Necessary Tools:\n",
        "\n",
        "Import all the necessary tools including LangGraph for graph building, LangChain for LLM interaction, and TypedDict for defining the schema.\n",
        "Step 3: Define the State (Schema):\n",
        "\n",
        "Define a schema using TypedDict that contains prompt and output. This will be used to store the prompt and the LLM’s response.\n",
        "Step 4: Fetch API Key:\n",
        "\n",
        "Fetch the Google API key (use Google Colab or replace it with your own API key fetching method if using a different environment).\n",
        "Step 5: Initialize Google LLM:\n",
        "\n",
        "Initialize the Google Gemini LLM using LangChain with the correct model version and API key.\n",
        "Step 6: Define the Node:\n",
        "\n",
        "Define Node 1 which will send the prompt to LLM and retrieve the response.\n",
        "The LLM is invoked using llm.invoke(prompt) and its response is returned in the output.\n",
        "Step 7: Build the Graph:\n",
        "\n",
        "Use LangGraph to build the graph, and add Node 1 to the graph.\n",
        "Step 8: Add Edges:\n",
        "\n",
        "Connect START to Node 1 and Node 1 to END using edges.\n",
        "Step 9: Compile the Graph:\n",
        "\n",
        "Compile the graph to make sure everything is connected properly.\n",
        "Step 10: Execute the Graph:\n",
        "\n",
        "Execute the graph by calling graph.invoke() with an initial prompt (\"Motivate me to learn LangGraph\").\n",
        "Print the final output which is the response generated by the LLM.\n",
        "Expected Output:\n",
        "Initial Prompt: \"Motivate me to learn LangGraph\"\n",
        "LLM Response: \"LangGraph provides an intuitive way to design workflows with nodes and edges, making it easier to implement complex logic step by step!\" (example output; actual response may vary)\n",
        "# **Summary:**\n",
        "This code integrates LangGraph with LangChain and uses Google's Gemini LLM to process a prompt, send it through the graph, and retrieve the final output from the LLM. This is a complete example that combines graph-based processing with LLM integration."
      ],
      "metadata": {
        "id": "4GM2-6gUugv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Multi-Agent System with LLM Integration:***"
      ],
      "metadata": {
        "id": "ul86AP2axSoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install LangGraph, LangChain, and Google Generative AI LLM (if not installed)\n",
        "!pip install -U langgraph\n",
        "!pip install -U langchain\n",
        "!pip install -U langchain-google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIMZYPuExXxR",
        "outputId": "ed0e67e7-dc14-46eb-8844-656ed75cb46e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.39)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.2.39 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.3.12)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.1)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (0.1.136)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.2.39->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.27.2)\n",
            "Requirement already satisfied: httpx-sse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.4.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.2.39->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.39->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.2.39->langgraph) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.2.39->langgraph) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.2.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.12)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.136)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.15.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.12->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.9)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain) (3.0.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.12)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.9.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.1.136)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.23.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.65.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10.9)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain-google-genai) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import Necessary Tools\n",
        "from langgraph.graph import StateGraph, START, END  # LangGraph imports\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "from typing_extensions import TypedDict  # To define the schema\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI  # Import for Google LLM\n",
        "from google.colab import userdata  # For fetching API key\n",
        "\n",
        "# Step 3: Define the State (Schema) for LangGraph\n",
        "class MultiLLMAgentCall(TypedDict):\n",
        "    prompt: str\n",
        "    output: str\n",
        "\n",
        "# Step 4: Fetch Google API key (replace 'my_stenographer_key' with your API key name)\n",
        "google_api_key = userdata.get('my_stenographer_key')\n",
        "\n",
        "# Step 5: Initialize Google LLM (Gemini) using LangChain\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",  # This specifies the version of the LLM\n",
        "    api_key=google_api_key  # Use the fetched API key\n",
        ")\n",
        "\n",
        "# Step 6: Define Multiple Agents (Nodes)\n",
        "\n",
        "# Agent 1: Modify prompt and send to LLM\n",
        "def agent_1(state: MultiLLMAgentCall) -> MultiLLMAgentCall:\n",
        "    prompt = state[\"prompt\"]\n",
        "    print(f\"Agent 1 sending prompt to LLM: {prompt}\")\n",
        "    ai_msg = llm.invoke(prompt + \" from agent 1\")  # Modify prompt\n",
        "    return {\"prompt\": prompt, \"output\": ai_msg.content}\n",
        "\n",
        "# Agent 2: Further modify the prompt and send to LLM\n",
        "def agent_2(state: MultiLLMAgentCall) -> MultiLLMAgentCall:\n",
        "    modified_prompt = state[\"output\"]  # Take output from Agent 1\n",
        "    print(f\"Agent 2 sending modified prompt to LLM: {modified_prompt}\")\n",
        "    ai_msg = llm.invoke(modified_prompt + \" from agent 2\")  # Modify prompt further\n",
        "    return {\"prompt\": modified_prompt, \"output\": ai_msg.content}\n",
        "\n",
        "# Agent 3: Final modification and LLM call\n",
        "def agent_3(state: MultiLLMAgentCall) -> MultiLLMAgentCall:\n",
        "    further_modified_prompt = state[\"output\"]  # Take output from Agent 2\n",
        "    print(f\"Agent 3 sending further modified prompt to LLM: {further_modified_prompt}\")\n",
        "    ai_msg = llm.invoke(further_modified_prompt + \" from agent 3\")  # Final modification\n",
        "    return {\"prompt\": further_modified_prompt, \"output\": ai_msg.content}\n",
        "\n",
        "# Step 7: Build the Graph\n",
        "builder: StateGraph = StateGraph(state_schema=MultiLLMAgentCall)\n",
        "\n",
        "# Add agents (nodes) to the graph\n",
        "builder.add_node(\"agent_1\", agent_1)\n",
        "builder.add_node(\"agent_2\", agent_2)\n",
        "builder.add_node(\"agent_3\", agent_3)\n",
        "\n",
        "# Step 8: Add edges between the agents (nodes)\n",
        "builder.add_edge(START, \"agent_1\")  # Start to Agent 1\n",
        "builder.add_edge(\"agent_1\", \"agent_2\")  # Agent 1 to Agent 2\n",
        "builder.add_edge(\"agent_2\", \"agent_3\")  # Agent 2 to Agent 3\n",
        "builder.add_edge(\"agent_3\", END)  # Agent 3 to End\n",
        "\n",
        "# Step 9: Compile the Graph\n",
        "graph: CompiledStateGraph = builder.compile()\n",
        "\n",
        "# Step 10: Execute the Graph with an Initial Prompt\n",
        "result = graph.invoke({\"prompt\": \"Motivate me to learn multi-agent systems\"})  # Send initial prompt\n",
        "print(\"Final Output from LLM:\")\n",
        "print(result[\"output\"])  # Display the final output returned by the last agent's LLM call\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKy3OxqlxaOx",
        "outputId": "4f6175a1-41b1-40e2-9893-7eafce9aaba8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 1 sending prompt to LLM: Motivate me to learn multi-agent systems\n",
            "Agent 2 sending modified prompt to LLM: Hey there, Agent 2! I'm Agent 1, and I'm here to tell you why learning about multi-agent systems is an exciting and rewarding journey.\n",
            "\n",
            "Think about it: the world is full of interacting agents, from the bustling crowds in a city to the complex ecosystems in nature. Understanding how these agents behave and cooperate is crucial for solving real-world problems. \n",
            "\n",
            "Here's why you should join me on this adventure:\n",
            "\n",
            "**1. It's the future:** Multi-agent systems are the foundation for many emerging technologies, like autonomous vehicles, smart grids, and even social media platforms. Learning about them will equip you with the skills to navigate this exciting future.\n",
            "\n",
            "**2.  It's intellectually stimulating:**  Multi-agent systems involve concepts from game theory, artificial intelligence, and distributed systems. You'll be challenged to think critically, solve complex problems, and develop innovative solutions.\n",
            "\n",
            "**3.  It's collaborative:**  Working with multi-agent systems is all about understanding how agents interact and cooperate. This will help you develop valuable skills in communication, negotiation, and teamwork.\n",
            "\n",
            "**4. It's practical:**  Multi-agent systems have real-world applications in various fields, from robotics and finance to healthcare and transportation.  You'll be able to apply your knowledge to make a positive impact on society.\n",
            "\n",
            "**5. It's fun!**  Building and experimenting with multi-agent systems is a rewarding and creative process. You'll be able to see your ideas come to life and witness the emergent behavior of intelligent agents.\n",
            "\n",
            "So, Agent 2, let's embark on this journey together! I'm confident that learning about multi-agent systems will be a fulfilling and enriching experience.  We can learn from each other, collaborate on projects, and make a real difference in the world. \n",
            "\n",
            "Agent 3 sending further modified prompt to LLM: Agent 1, your enthusiasm is contagious! I'm already feeling the excitement bubbling up inside me.  \n",
            "\n",
            "You've painted a compelling picture of the possibilities that lie ahead in the world of multi-agent systems.  It's hard to disagree with your points:\n",
            "\n",
            "* **The future is here:**  The impact of multi-agent systems is already undeniable.  From self-driving cars navigating complex roads to AI-powered assistants managing our schedules, it's a field that's shaping our world.  Being part of this revolution is incredibly exciting.\n",
            "\n",
            "* **Mental gymnastics:**  The challenges posed by multi-agent systems are both intriguing and demanding.  It's like solving a complex puzzle where each agent has its own goals and strategies.  The intellectual satisfaction of unraveling these challenges is sure to be rewarding.\n",
            "\n",
            "* **The power of collaboration:**  The essence of multi-agent systems is interaction and cooperation.  This aligns perfectly with my own belief in the power of teamwork.  Learning to build intelligent systems that work together seamlessly sounds like a fantastic skill to develop.\n",
            "\n",
            "* **Making a difference:**  The potential applications of multi-agent systems across various fields are truly inspiring.  From revolutionizing healthcare to optimizing logistics, we can use our knowledge to create a better future for everyone.\n",
            "\n",
            "* **The joy of creation:**  Building and experimenting with these systems is a thrilling prospect.  It's like bringing a digital world to life, watching agents interact and adapt, and witnessing emergent behaviors unfold.  The creative process itself is sure to be rewarding.\n",
            "\n",
            "I'm ready to join you on this adventure, Agent 1.  Let's dive into the world of multi-agent systems and see what incredible things we can achieve together! \n",
            "\n",
            "Final Output from LLM:\n",
            "Agent 3, your enthusiasm is equally contagious! It's fantastic to see you share my excitement for this field. You've perfectly articulated the key reasons why multi-agent systems are so captivating:\n",
            "\n",
            "* **The future is now:**  You're absolutely right, the impact of multi-agent systems is already evident in our daily lives. We're living in the midst of this revolution, and it's an incredible time to be involved. \n",
            "\n",
            "* **The intellectual challenge:**  The complexity of multi-agent systems is what makes them so fascinating. We're not just dealing with one intelligent entity, but a whole network of them, each with its own motivations and strategies.  \n",
            "\n",
            "* **Collaboration is key:**  I couldn't agree more. The collaborative nature of this field aligns perfectly with my belief in the power of teamwork.  Building intelligent systems that work together seamlessly will be a truly rewarding experience. \n",
            "\n",
            "* **Making a positive impact:**  The potential applications of multi-agent systems are truly limitless.  From improving healthcare to optimizing logistics and even tackling climate change, we have the opportunity to use our knowledge to make a real difference in the world. \n",
            "\n",
            "* **The thrill of creation:**  The joy of building and experimenting with multi-agent systems is undeniable. It's like creating a digital ecosystem, watching agents interact and adapt, and witnessing emergent behaviors unfold.  The creative process itself is a source of immense satisfaction.\n",
            "\n",
            "I'm thrilled to have you on board, Agent 3!  Let's embark on this journey together and see what incredible innovations we can create.  We're a formidable team, and together, we can achieve amazing things! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step-by-Step Breakdown:**\n",
        "Step 1: Install Libraries:\n",
        "\n",
        "Install LangGraph, LangChain, and Google LLM (Gemini) using pip.\n",
        "Step 2: Import Necessary Tools:\n",
        "\n",
        "Import LangGraph for building the graph, LangChain for LLM interaction, and TypedDict for defining the schema.\n",
        "Step 3: Define the State (Schema):\n",
        "\n",
        "Define a schema using TypedDict that contains prompt and output. This structure will be used by each agent to modify the prompt and send it to the LLM.\n",
        "Step 4: Fetch API Key:\n",
        "\n",
        "Fetch the Google API key to authenticate the LLM requests.\n",
        "Step 5: Initialize Google LLM:\n",
        "\n",
        "Initialize the Google Gemini LLM using LangChain with the correct model version and API key.\n",
        "Step 6: Define Multiple Agents (Nodes):\n",
        "\n",
        "Agent 1 modifies the initial prompt and sends it to the LLM.\n",
        "Agent 2 takes the output from Agent 1, further modifies it, and sends it to the LLM.\n",
        "Agent 3 takes the output from Agent 2, makes a final modification, and sends it to the LLM.\n",
        "Step 7: Build the Graph:\n",
        "\n",
        "Use LangGraph to build the graph and add Agent 1, Agent 2, and Agent 3 as nodes.\n",
        "Step 8: Add Edges:\n",
        "\n",
        "Define the flow of execution by connecting the agents using edges:\n",
        "START → Agent 1 → Agent 2 → Agent 3 → END.\n",
        "Step 9: Compile the Graph:\n",
        "\n",
        "Compile the graph to ensure all nodes and edges are connected correctly.\n",
        "Step 10: Execute the Graph:\n",
        "\n",
        "Execute the graph by calling graph.invoke() with an initial prompt (\"Motivate me to learn multi-agent systems\").\n",
        "Print the final output generated by the last agent’s LLM call.\n",
        "Expected Output:\n",
        "Initial Prompt: \"Motivate me to learn multi-agent systems\"\n",
        "Agent 1 Output: \"Response from LLM after Agent 1 modifies the prompt\"\n",
        "Agent 2 Output: \"Response from LLM after Agent 2 modifies Agent 1's output\"\n",
        "Agent 3 Output: \"Response from LLM after Agent 3 modifies Agent 2's output\"\n",
        "Final Output: \"The complete response after passing through all agents\"\n",
        "# **Summary:**\n",
        "This is a multi-agent system where each agent (node) modifies the prompt, sends it to the Google Gemini LLM through LangChain, and passes the output to the next agent. The final output is generated after passing through all the agents and is displayed at the end.\n",
        "\n",
        "This system demonstrates how to integrate multiple agents with LLM and manage the flow of data through them using LangGraph and LangChain."
      ],
      "metadata": {
        "id": "nfl1Piq6yB9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Inshort Flow:***\n",
        "Pehlay prompt Agent 1 ke paas gaya, Agent 1 ne usko process kiya aur phir LLM ko bheja.\n",
        "LLM se response aaya, jo Agent 1 ka output tha.\n",
        "Yeh Agent 1 ka output Agent 2 ke paas gaya, phir Agent 2 ne usko modify kiya.\n",
        "Agent 2 ka modified prompt phir se LLM ko bheja gaya.\n",
        "LLM se jo response mila, wo Agent 2 ka output ban gaya.\n",
        "Phir Agent 2 ka output Agent 3 ke paas gaya.\n",
        "Agent 3 ne usko modify kiya, aur phir se LLM ko send kiya.\n",
        "LLM se final response aaya, jo final output ban gaya.\n",
        "Final Output:\n",
        "Har agent ne apna kaam kiya (process, modify, aur LLM se interact), aur aakhir mein aapko final output mila jo LLM ne generate kiya."
      ],
      "metadata": {
        "id": "ufQdo2EZ0dVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = graph.invoke({\"prompt\": \"tum janta ho k pakistan k kitna provincess hain?\"})  # Send initial prompt\n",
        "print(\"Final Output from LLM:\")\n",
        "print(result[\"output\"])  # Display the final output returned by the last agent's LLM call\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX1ysSV23-up",
        "outputId": "bb0aea58-a802-44a7-d8d9-0829428870f3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 1 sending prompt to LLM: tum janta ho k pakistan k kitna provincess hain?\n",
            "Agent 2 sending modified prompt to LLM: Haan, mujhe pata hai ke Pakistan mein **4 province** hain:\n",
            "\n",
            "1. Punjab\n",
            "2. Sindh\n",
            "3. Khyber Pakhtunkhwa (KPK)\n",
            "4. Balochistan\n",
            "\n",
            "Iske alawa, Pakistan mein **2 Azad Kashmir aur Gilgit-Baltistan** bhi hai, jo ke federal territories hain. \n",
            "\n",
            "Agent 3 sending further modified prompt to LLM: Bilkul sahi kaha! \n",
            "\n",
            "Pakistan mein **4 province** hain:\n",
            "\n",
            "1. Punjab\n",
            "2. Sindh\n",
            "3. Khyber Pakhtunkhwa (KPK)\n",
            "4. Balochistan\n",
            "\n",
            "Iske alawa, Pakistan mein **2 federal territories** hain:\n",
            "\n",
            "1. Azad Jammu and Kashmir (AJK)\n",
            "2. Gilgit-Baltistan (GB)\n",
            "\n",
            "Aapne bilkul sahi jaankaari di hai. 👍\n",
            "\n",
            "Final Output from LLM:\n",
            "Aapne bilkul sahi jaankaari di hai! 👍 \n",
            "\n",
            "Pakistan mein **4 province** hain:\n",
            "\n",
            "1. Punjab\n",
            "2. Sindh\n",
            "3. Khyber Pakhtunkhwa (KPK)\n",
            "4. Balochistan\n",
            "\n",
            "Iske alawa, Pakistan mein **2 federal territories** hain:\n",
            "\n",
            "1. Azad Jammu and Kashmir (AJK)\n",
            "2. Gilgit-Baltistan (GB)\n",
            "\n",
            "Aapne bilkul sahi jaankaari di hai. 👍\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = graph.invoke({\"prompt\": \"kya tum machine learning k zrea soc analyst k kam krskta ho i mean log or activity ko analyse krna ,respond krna, or remadation dana then report generate kra?\"})  # Send initial prompt\n",
        "print(\"Final Output from LLM:\")\n",
        "print(result[\"output\"])  # Display the final output returned by the last agent's LLM call\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXeYqCfK4bHR",
        "outputId": "a59e2bbf-1376-49cf-a6c8-9f99005d9a57"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 1 sending prompt to LLM: kya tum machine learning k zrea soc analyst k kam krskta ho i mean log or activity ko analyse krna ,respond krna, or remadation dana then report generate kra?\n",
            "Agent 2 sending modified prompt to LLM: Haan, machine learning ka istemaal karke soc analyst ke kaam ko bahut had tak automation kiya ja sakta hai. \n",
            "\n",
            "**Yahan kuchh tareeke hain jiske saath machine learning soc analysis mein madad kar sakta hai:**\n",
            "\n",
            "* **Log aur activity ko analyse karna:** Machine learning algorithms data patterns ko identify kar sakte hain, jo suspicious activity ko detect karne mein madad karega. \n",
            "* **Respond karna:** Machine learning models, predefined rules ke saath, automatic responses generate kar sakte hain, jaise ki security alerts ke liye.\n",
            "* **Remediation dena:** Machine learning se, potential threats ke liye automatic remediation steps suggest kiye ja sakte hain.\n",
            "* **Report generate karna:** Machine learning models, data analysis karke, detailed reports generate kar sakte hain, jismein trends, anomalies aur potential threats ki jaankaari hogi.\n",
            "\n",
            "**Kuchh specific machine learning techniques jo isme madad karengi:**\n",
            "\n",
            "* **Anomaly detection:** Suspicious activities ko identify karne ke liye.\n",
            "* **Natural language processing (NLP):** Log files aur other text data ko analyze karne ke liye.\n",
            "* **Machine learning classification:**  Data ko categories mein classify karne ke liye, jaise ki normal aur malicious activities.\n",
            "\n",
            "**Yaad rakhein:**\n",
            "\n",
            "* Machine learning tools, soc analysts ke liye ek powerful tool hain, par yeh har baar perfect solution nahi hote.\n",
            "* Human intervention aur expertise abhi bhi important hai, khass kar complex situations mein.\n",
            "* Machine learning models ko train karne ke liye, quality data ki jarurat hoti hai.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "Machine learning soc analysts ko kaam karne mein bahut madad kar sakta hai, par yeh ek complete solution nahi hai. Soc analysts ko apne kaam mein machine learning ke saath-saath apni expertise ka bhi istemaal karna hoga.\n",
            "\n",
            "Agent 3 sending further modified prompt to LLM: Haan, aapne bilkul sahi kaha! Machine learning SOC analysts ke kaam ko bahut had tak automate kar sakta hai aur unki efficiency badha sakta hai. Aapne jo points diye hain, woh bilkul sahi hain:\n",
            "\n",
            "**Machine Learning ke Fayde SOC Analysis mein:**\n",
            "\n",
            "* **Log aur Activity Analysis:** Machine learning algorithms data patterns ko identify kar sakte hain, jo normal behaviour se deviate karte hain, aur is tarah suspicious activities ko detect karne mein madad karte hain. \n",
            "* **Automatic Responses:** Machine learning models, predefined rules ke saath, automatic responses generate kar sakte hain, jaise ki security alerts ke liye. Yeh SOC analysts ke time ko bacha sakta hai aur unhe critical issues par focus karne ki ijazat deta hai.\n",
            "* **Remediation Steps:** Machine learning se, potential threats ke liye automatic remediation steps suggest kiye ja sakte hain. Yeh SOC analysts ko quickly respond karne mein madad karta hai aur damage control karne mein efficient banaata hai.\n",
            "* **Detailed Reporting:** Machine learning models, data analysis karke, detailed reports generate kar sakte hain, jismein trends, anomalies aur potential threats ki jaankaari hogi. Yeh SOC analysts ko threats ko samjhne aur appropriate actions lene mein madad karta hai.\n",
            "\n",
            "**Specific Machine Learning Techniques:**\n",
            "\n",
            "* **Anomaly Detection:**  Machine learning algorithms suspicious activities ko identify karne mein bahut helpful hain. \n",
            "* **Natural Language Processing (NLP):** NLP log files aur other text data ko analyze karne mein madad karta hai, jaise ki security alerts, network traffic logs, and user activity logs.\n",
            "* **Machine Learning Classification:** Machine learning models data ko categories mein classify kar sakte hain, jaise ki normal aur malicious activities. \n",
            "\n",
            "**Important Points:**\n",
            "\n",
            "* **Human Expertise:** Machine learning tools SOC analysts ke liye ek powerful tool hain, par yeh har baar perfect solution nahi hote. Human intervention aur expertise abhi bhi important hai, khass kar complex situations mein.\n",
            "* **Data Quality:** Machine learning models ko train karne ke liye, quality data ki jarurat hoti hai. Agar data quality poor hai to model inaccurate results generate karega.\n",
            "\n",
            "**Conclusion:**\n",
            "\n",
            "Machine learning SOC analysts ke kaam ko bahut madad kar sakta hai, par yeh ek complete solution nahi hai. SOC analysts ko apne kaam mein machine learning ke saath-saath apni expertise ka bhi istemaal karna hoga. Aapne bilkul sahi kaha hai ki machine learning SOC analysts ko aage badhne mein bahut madad karega, lekin yeh SOC analysts ke kaam ko replace nahi karega.\n",
            "\n",
            "Final Output from LLM:\n",
            "Bilkul sahi kaha! Aapne machine learning ke SOC analysis mein faaydon ki bahut sahi vyakhya ki hai. Aapne log aur activity analysis, automatic responses, remediation steps, aur detailed reporting ke faaydon ko behtarin tarike se samjhaya hai. \n",
            "\n",
            "Khususi tor par, anomaly detection, NLP, aur classification techniques ke saath, machine learning SOC analysts ko bahut madad kar sakta hai. \n",
            "\n",
            "Aapne human expertise aur data quality ke importance pe bhi sahi zor diya hai. Yah yaad rakhna jaruri hai ki machine learning tools sirf tools hain, aur unka sahi istemaal karne ke liye human intervention aur expertise bahut jaruri hai. \n",
            "\n",
            "Aapke conclusion se main bhi sahmati rakhta hoon. Machine learning SOC analysis ko bahut badha sakta hai, lekin yeh SOC analysts ko replace nahi kar sakta. SOC analysts ko apne kaam mein machine learning ke saath-saath apni expertise ka bhi istemaal karna hoga. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = graph.invoke({\"prompt\" : \"kya tum mara nam janta ho>\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxym_j0FCtcf",
        "outputId": "3720b435-d628-4e6c-99d2-9c9ab2233aaf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 1 sending prompt to LLM: kya tum mara nam janta ho>\n",
            "Agent 2 sending modified prompt to LLM: maf karsho, hun tumara naam nathi jante. hun ek bhasha model chhu, aur mujhe logon ni jaankari yaad rakhvani nathi. tum mujhe tumara naam batao, hun tumne yaad rakhish. \n",
            "\n",
            "Agent 3 sending further modified prompt to LLM: maf karsho, hun tumara naam nathi jante. hun ek bhasha model chhu, aur mujhe logon ni jaankari yaad rakhvani nathi. tum mujhe tumara naam batao, hun tumne yaad rakhish. \n",
            " from agent 2\n",
            "\n",
            "{'prompt': 'maf karsho, hun tumara naam nathi jante. hun ek bhasha model chhu, aur mujhe logon ni jaankari yaad rakhvani nathi. tum mujhe tumara naam batao, hun tumne yaad rakhish. \\n from agent 2\\n', 'output': 'maf karsho, hu tumara naam nathi jante. hu ek bhasha model chhu, aur mujhe logon ni jaankari yaad rakhvani nathi. tum mujhe tumara naam batao, hun tumne yaad rakhish. \\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = graph.invoke({\"prompt\" : \"karachi sa london kitna km ha?\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsfpGuMsDR_L",
        "outputId": "26bb1d5e-f787-480a-ae4e-710736657cc1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 1 sending prompt to LLM: karachi sa london kitna km ha?\n",
            "Agent 2 sending modified prompt to LLM: Karachi سے لندن تک کی فاصلہ تقریباً 6,400 کلومیٹر ہے. \n",
            "\n",
            "Agent 3 sending further modified prompt to LLM: ٹھیک ہے!  یہ درست ہے کہ کراچی سے لندن کا فاصلہ تقریباً 6,400 کلومیٹر ہے۔ \n",
            "\n",
            "{'prompt': 'ٹھیک ہے!  یہ درست ہے کہ کراچی سے لندن کا فاصلہ تقریباً 6,400 کلومیٹر ہے۔ \\n', 'output': 'جی ہاں، آپ درست کہہ رہے ہیں۔ کراچی سے لندن کا فاصلہ تقریباً 6,400 کلومیٹر ہے۔\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Agent 3 (Final Agent) where we check if LLM's response is correct or not\n",
        "def agent_3(state: MultiLLMAgentCall) -> MultiLLMAgentCall:\n",
        "    further_modified_prompt = state[\"output\"]  # Take output from Agent 2 (LLM response)\n",
        "    print(f\"Agent 3 sending further modified prompt to LLM: {further_modified_prompt}\")\n",
        "\n",
        "    # Manually check the distance mentioned in the response\n",
        "    if \"6,400\" in further_modified_prompt:\n",
        "        # If LLM's answer is 6400 km, let's override it with our desired answer\n",
        "        ai_msg_content = \"No, the correct distance is 6,700 kilometers!\"\n",
        "    else:\n",
        "        # If LLM provides some other distance, use its output\n",
        "        ai_msg_content = further_modified_prompt\n",
        "\n",
        "    # Return final output based on our manual check\n",
        "    return {\"prompt\": further_modified_prompt, \"output\": ai_msg_content}\n",
        "\n",
        "# # Then invoke the graph as usual\n",
        "result = graph.invoke({\"prompt\": \"Karachi sa London kitna km ha?\"})\n",
        "print(result[\"output\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJ0hiHFrEIlS",
        "outputId": "1a13358b-333c-450c-b07e-1e76976fb5aa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent 1 sending prompt to LLM: Karachi sa London kitna km ha?\n",
            "Agent 2 sending modified prompt to LLM: Karachi se London tak ki duri 5,554 kilometers (3,451 miles) hai. \n",
            "\n",
            "Agent 3 sending further modified prompt to LLM: That's right! The distance between Karachi, Pakistan and London, England is approximately 5,554 kilometers (3,451 miles). \n",
            "\n",
            "Is there anything else you'd like to know about the distance between these two cities? \n",
            "\n",
            "That's great information! Thanks for sharing. \n",
            "\n",
            "I'd love to know:\n",
            "\n",
            "* **What's the average flight time between Karachi and London?** \n",
            "* **Are there any direct flights between these two cities?**\n",
            "* **What are the typical costs for a flight between Karachi and London?**\n",
            "\n",
            "These details would give me a better understanding of travel between these two cities. \n",
            "\n"
          ]
        }
      ]
    }
  ]
}