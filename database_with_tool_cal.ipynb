{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLcCFIq0VCpJ9E41pxLazJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAVEED261/MY-AI-ASSISTANT/blob/main/database_with_tool_cal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qFeVbJnraVAf"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langgraph langgraph-checkpoint-postgres psycopg psycopg-pool langchain_google_genai\n",
        "\n",
        "from google.colab import userdata\n",
        "GEMINI_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "import os\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('Langchain_api_key')\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\"\n",
        "\n",
        "from psycopg_pool import ConnectionPool\n",
        "from langgraph.checkpoint.postgres import PostgresSaver\n",
        "\n",
        "# Set up PostgreSQL Database\n",
        "DB_URI = userdata.get('DB_URI')\n",
        "connection_kwargs = {\"autocommit\": True, \"prepare_threshold\": 0}\n",
        "pool = ConnectionPool(conninfo=DB_URI, max_size=20, kwargs=connection_kwargs)\n",
        "checkpointer = PostgresSaver(pool)\n",
        "checkpointer.setup()\n",
        "\n",
        "# Define Tools\n",
        "from langchain_core.tools import Tool\n",
        "\n",
        "# Tool 1: Fetch Product Details\n",
        "def get_product_details(product_id: str) -> str:\n",
        "    products = {\n",
        "        \"P101\": {\"name\": \"Laptop\", \"price\": 10600.0, \"stock\": 5},\n",
        "        \"P102\": {\"name\": \"Smartphone\", \"price\": 7500.0, \"stock\": 0},\n",
        "    }\n",
        "    product = products.get(product_id)\n",
        "    if not product:\n",
        "        return \"Product not found.\"\n",
        "    return f\"Name: {product['name']}, Price: ${product['price']}, Stock: {product['stock']} units.\"\n",
        "\n",
        "# Tool 2: Calculate Shipping Cost\n",
        "def calculate_shipping_cost(distance: float, weight: float) -> float:\n",
        "    rate_per_km_per_kg = 5.0\n",
        "    return distance * weight * rate_per_km_per_kg\n",
        "\n",
        "# Register Tools\n",
        "tools = [\n",
        "    Tool(name=\"get_product_details\", func=get_product_details, description=\"Fetch product details by ID.\"),\n",
        "    Tool(name=\"calculate_shipping_cost\", func=calculate_shipping_cost, description=\"Calculate shipping cost.\"),\n",
        "]\n",
        "\n",
        "# Initialize Model with Tools\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", api_key=GEMINI_API_KEY)\n",
        "llm_with_tools = model.bind_tools(tools)\n",
        "\n",
        "# Define Custom State\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from IPython.display import Image\n",
        "\n",
        "class State(MessagesState):\n",
        "    summary: str\n",
        "\n",
        "# Model Logic\n",
        "def call_model_with_tools(state: State) -> State:\n",
        "    messages = state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "# Summarize Conversation\n",
        "def summarize_conversation(state: State) -> State:\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "    summary_message = (\n",
        "        f\"Extend the summary by taking into account the new messages above:\\n{summary}\"\n",
        "        if summary else \"Create a summary of the conversation above:\"\n",
        "    )\n",
        "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
        "    response = model.invoke(messages)\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
        "\n",
        "# Workflow Logic\n",
        "def should_continue(state: State) -> str:\n",
        "    if len(state[\"messages\"]) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "    return END\n",
        "\n",
        "# Define Graph\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"conversation\", call_model_with_tools)\n",
        "workflow.add_node(\"tools\", ToolNode(tools))\n",
        "workflow.add_node(\"summarize_conversation\", summarize_conversation)\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_edge(\"conversation\", \"tools\")\n",
        "workflow.add_edge(\"tools\", \"summarize_conversation\")\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "# Compile Workflow with Database Checkpointer\n",
        "graph = workflow.compile(checkpointer=checkpointer)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
        "\n",
        "# Start conversation\n",
        "input_message = HumanMessage(content=\"Show me the details of product P101\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for m in output['messages']:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDmLRmgccFLv",
        "outputId": "f2e86604-4236-4b1b-89ee-b974c43c9351"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  get_product_details (9606206f-762d-475e-8cc2-3649a283f26c)\n",
            " Call ID: 9606206f-762d-475e-8cc2-3649a283f26c\n",
            "  Args:\n",
            "    __arg1: P101\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: get_product_details\n",
            "\n",
            "Name: Laptop, Price: $10600.0, Stock: 5 units.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = HumanMessage(content=\"What is the shipping cost for 100 km and 2 kg?\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for m in output['messages']:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwQ1klZzcU09",
        "outputId": "4159c603-6db5-4ae0-f95b-14a8af68ff81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  calculate_shipping_cost (8cdd3138-6023-486b-a9c4-e51adcc66b61)\n",
            " Call ID: 8cdd3138-6023-486b-a9c4-e51adcc66b61\n",
            "  Args:\n",
            "    __arg1: 100km,2kg\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: calculate_shipping_cost\n",
            "\n",
            "Error: TypeError(\"calculate_shipping_cost() missing 1 required positional argument: 'weight'\")\n",
            " Please fix your mistakes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = HumanMessage(content=\"I want to buy a laptop (P101). Can you confirm its price, availability, calculate the shipping cost for 15 km with a weight of 2.5 kg, and also add a review saying, 'Great performance!'?\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for m in output['messages']:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkJ6ZSoLc3jn",
        "outputId": "caa739c0-b872-4f3d-d1c7-f32ec576f0fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "I want to buy a laptop (P101). Can you confirm its price, availability, calculate the shipping cost for 15 km with a weight of 2.5 kg, and also add a review saying, 'Great performance!'?\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I cannot fulfill this request completely. I can get the price and availability of the laptop if you provide the necessary API calls or data structures.  I also cannot add a review as there is no such functionality available in the provided APIs.  I can calculate the shipping cost if the `calculate_shipping_cost` function is updated to accept distance and weight as parameters.  The current function is not usable.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = HumanMessage(content=\"Calculates the shipping cost for 15 km and 2.5 kg.\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for m in output['messages']:\n",
        "    m.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O5cY083dyBg",
        "outputId": "b1a52ed3-fb0a-405b-d6fb-1ea9259bf3a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Calculates the shipping cost for 15 km and 2.5 kg.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I cannot perform this calculation. The available function `calculate_shipping_cost` does not accept distance and weight as parameters.  To calculate the shipping cost, I need either a function that takes distance and weight as input or a pricing model.\n"
          ]
        }
      ]
    }
  ]
}