{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJHHOUJRYtrWDDjYEC3nfj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAVEED261/MY-AI-ASSISTANT/blob/main/successfuly_deploying_of_local_to_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FBIGL-yl_i9z"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_google_genai langgraph_sdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "%env GOOGLE_API_KEY = {userdata.get('GEMINI_API_KEY')}\n",
        "\n",
        "import os\n",
        "print(os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsSPaIkA_ru2",
        "outputId": "453f3b10-6d9a-4cae-ba9d-fb6291bb0526"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_API_KEY={userdata.get('GEMINI_API_KEY')}\n",
            "{userdata.get('GEMINI_API_KEY')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env LANGCHAIN_API_KEY = {userdata.get('LANGCHAIN_API_KEY')}\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNy5QY6u_tTd",
        "outputId": "36a3146b-fd09-42b4-ecf9-32bb952a33af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LANGCHAIN_API_KEY={userdata.get('LANGCHAIN_API_KEY')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langgraph_sdk import get_client\n",
        "from langgraph_sdk import get_client\n",
        "# The URL provided below is invalid, please provide a valid url.\n",
        "URL = 'https://9f15-2404-3100-140f-7e04-317e-300c-d6d1-5095.ngrok-free.app'\n",
        "client = get_client(url = URL)\n",
        "assistants = await client.assistants.search()"
      ],
      "metadata": {
        "id": "i30ff7A8Bv4v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, convert_to_messages\n",
        "thread = await client.threads.create()\n",
        "input_messages = HumanMessage(content=\"Multiply 4  and 9\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],assistant_id=\"agent\",input = {\"messages\":[input_messages]},stream_mode=\"values\"):\n",
        "  print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHWaJi_BCujI",
        "outputId": "94aa2c15-f91a-45fb-81e0-67cbd4b8f1de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StreamPart(event='metadata', data={'run_id': '1efcd9b8-9a2e-624d-a17e-025089d3b290', 'attempt': 1})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 4  and 9', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4f2c07d3-540f-405a-9cc7-4d9516db35a7', 'example': False}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 4  and 9', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4f2c07d3-540f-405a-9cc7-4d9516db35a7', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 4.0, \"b\": 9.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-9b0b03f8-3fbb-42da-abad-b63eee7674e6-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 4.0, 'b': 9.0}, 'id': '0e4fd967-90ca-4a13-8f48-5fc194e50a0b', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 169, 'output_tokens': 3, 'total_tokens': 172, 'input_token_details': {'cache_read': 0}}}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 4  and 9', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4f2c07d3-540f-405a-9cc7-4d9516db35a7', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 4.0, \"b\": 9.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-9b0b03f8-3fbb-42da-abad-b63eee7674e6-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 4.0, 'b': 9.0}, 'id': '0e4fd967-90ca-4a13-8f48-5fc194e50a0b', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 169, 'output_tokens': 3, 'total_tokens': 172, 'input_token_details': {'cache_read': 0}}}, {'content': '36', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '91d784d5-497a-463c-af12-acfdd217a7ef', 'tool_call_id': '0e4fd967-90ca-4a13-8f48-5fc194e50a0b', 'artifact': None, 'status': 'success'}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 4  and 9', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '4f2c07d3-540f-405a-9cc7-4d9516db35a7', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 4.0, \"b\": 9.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-9b0b03f8-3fbb-42da-abad-b63eee7674e6-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 4.0, 'b': 9.0}, 'id': '0e4fd967-90ca-4a13-8f48-5fc194e50a0b', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 169, 'output_tokens': 3, 'total_tokens': 172, 'input_token_details': {'cache_read': 0}}}, {'content': '36', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '91d784d5-497a-463c-af12-acfdd217a7ef', 'tool_call_id': '0e4fd967-90ca-4a13-8f48-5fc194e50a0b', 'artifact': None, 'status': 'success'}, {'content': 'The result is 36.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-a1b9fc99-e363-47b9-9732-a2d3189fdecc-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 203, 'output_tokens': 8, 'total_tokens': 211, 'input_token_details': {'cache_read': 0}}}]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, convert_to_messages\n",
        "thread = await client.threads.create()\n",
        "input_messages = HumanMessage(content=\"Multiply 4  and 9\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],assistant_id=\"agent\",input = {\"messages\":[input_messages]},stream_mode=\"messages\"):\n",
        "  print(event.event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbraSQSvDpJi",
        "outputId": "641afde7-9437-4570-8be3-7cecc2cb1995"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadata\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/metadata\n",
            "messages/complete\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, convert_to_messages\n",
        "thread = await client.threads.create()\n",
        "input_messages = HumanMessage(content=\"Multiply 4  and 9\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],assistant_id=\"agent\",input = {\"messages\":[input_messages]},stream_mode=\"values\"):\n",
        "   messages = event.data.get('messages',None)\n",
        "   if messages:\n",
        "        print(convert_to_messages(messages)[-1])\n",
        "   print('='*25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km55VUDkDx5G",
        "outputId": "af8c311e-7383-4c9f-ae7b-4698c246333f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================\n",
            "content='Multiply 4  and 9' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} response_metadata={} id='7389c25f-2def-44b9-996c-feab7b2d055c'\n",
            "=========================\n",
            "content='' additional_kwargs={'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 4.0, \"b\": 9.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 169, 'output_tokens': 3, 'total_tokens': 172, 'input_token_details': {'cache_read': 0}}} response_metadata={} id='run-38918e6b-1b86-4e48-95c3-555143b0eecc-0' tool_calls=[{'name': 'multiply', 'args': {'a': 4.0, 'b': 9.0}, 'id': '470ac40d-9f79-4aa9-a05c-a0c0af230d11', 'type': 'tool_call'}]\n",
            "=========================\n",
            "content='36' name='multiply' id='983df7a1-6b4e-4e1f-b115-8d38fd830305' tool_call_id='470ac40d-9f79-4aa9-a05c-a0c0af230d11'\n",
            "=========================\n",
            "content='The result is 36.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 203, 'output_tokens': 7, 'total_tokens': 210, 'input_token_details': {'cache_read': 0}}} response_metadata={} id='run-cb1bf217-7470-4a98-8f6f-2780bd588ed3-0'\n",
            "=========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "\n",
        "def format_tool_calls(tool_calls):\n",
        "    \"\"\"\n",
        "    Format a list of tool calls into a readable string.\n",
        "\n",
        "    Args:\n",
        "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
        "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if tool_calls:\n",
        "        formatted_calls = []\n",
        "        for call in tool_calls:\n",
        "            formatted_calls.append(\n",
        "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
        "            )\n",
        "        return \"\\n\".join(formatted_calls)\n",
        "    return \"No tool calls\"\n",
        "\n",
        "async for event in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input={\"messages\": [input_message]},\n",
        "    stream_mode=\"messages\",):\n",
        "\n",
        "    # Handle metadata events\n",
        "    if event.event == \"metadata\":\n",
        "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Handle partial message events\n",
        "    elif event.event == \"messages/partial\":\n",
        "        for data_item in event.data:\n",
        "            # Process user messages\n",
        "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
        "                print(f\"Human: {data_item['content']}\")\n",
        "            else:\n",
        "                # Extract relevant data from the event\n",
        "                tool_calls = data_item.get(\"tool_calls\", [])\n",
        "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
        "                content = data_item.get(\"content\", \"\")\n",
        "                response_metadata = data_item.get(\"response_metadata\", {})\n",
        "\n",
        "                if content:\n",
        "                    print(f\"AI: {content}\")\n",
        "\n",
        "                if tool_calls:\n",
        "                    print(\"Tool Calls:\")\n",
        "                    print(format_tool_calls(tool_calls))\n",
        "\n",
        "                if invalid_tool_calls:\n",
        "                    print(\"Invalid Tool Calls:\")\n",
        "                    print(format_tool_calls(invalid_tool_calls))\n",
        "\n",
        "                if response_metadata:\n",
        "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
        "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
        "\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zagaNRwEvlm",
        "outputId": "d20c2882-9077-4072-867c-325012fecf30"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata: Run ID - 1efcd9c4-a74a-6f13-aa4e-0900ddc68141\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: 3f57722c-d872-4da2-93e6-73727fe5cd42, Function: multiply, Arguments: {'a': 2.0, 'b': 3.0}\n",
            "Response Metadata: Finish Reason - N/A\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: 3f57722c-d872-4da2-93e6-73727fe5cd42, Function: multiply, Arguments: {'a': 2.0, 'b': 3.0}\n",
            "Response Metadata: Finish Reason - STOP\n",
            "--------------------------------------------------\n",
            "AI: The\n",
            "Response Metadata: Finish Reason - N/A\n",
            "--------------------------------------------------\n",
            "AI: The result is 6.\n",
            "Response Metadata: Finish Reason - STOP\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}