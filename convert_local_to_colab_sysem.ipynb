{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlr7SQhuGPn9x4CX9Jcxit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAVEED261/MY-AI-ASSISTANT/blob/main/convert_local_to_colab_sysem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SsGz4KdroydJ"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_google_genai langgraph_sdk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "%env GOOGLE_API_KEY = {userdata.get('GOOGLE_API_KEY')}\n",
        "\n",
        "import os\n",
        "print(os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "%env LANGCHAIN_API_KEY = {userdata.get('Langchain_api_key')}\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J-7LzVDo6D2",
        "outputId": "75f24c6e-ac9f-40ca-e597-33f656541c89"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_API_KEY=AIzaSyDb6CykOlbZQVP6IGM55P6uiAwcfxUzOJY\n",
            "AIzaSyDb6CykOlbZQVP6IGM55P6uiAwcfxUzOJY\n",
            "env: LANGCHAIN_API_KEY=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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\")\n",
        "model.invoke(\"hi how r u\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5RES9mVpMgk",
        "outputId": "f5b34793-b671-47af-ce80-ab50a95055c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"I'm doing well, thank you for asking!  How are you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-fe2e2b6b-c118-427f-921f-2d812ddfb816-0', usage_metadata={'input_tokens': 5, 'output_tokens': 18, 'total_tokens': 23, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph_sdk import get_client\n",
        "\n",
        "# Replace this with the URL of your own deployed graph\n",
        "URL = \"https://61e5-202-59-12-97.ngrok-free.app\"\n",
        "client = get_client(url=URL)\n",
        "\n",
        "# Search all hosted graphs\n",
        "assistants = await client.assistants.search()"
      ],
      "metadata": {
        "id": "oAvl57M-pZ2T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage, AIMessage\n",
        "thread = await client.threads.create()\n",
        "# Input message\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],\n",
        "                                      assistant_id=\"agent\",\n",
        "                                      input={\"messages\": [input_message]},\n",
        "                                      stream_mode=\"values\"):\n",
        "    print(event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLwTKYk_pdus",
        "outputId": "642f2db0-3fea-4c7c-d6bf-15a958400276"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StreamPart(event='metadata', data={'run_id': '1efcd8bb-568f-67dc-a7c8-b2990f52d3ff', 'attempt': 1})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '601638f8-2323-4dbb-98b1-3726b412c2f1', 'example': False}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '601638f8-2323-4dbb-98b1-3726b412c2f1', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-bf274fe1-edfd-4248-b785-109e9a3b02df-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'e0f61746-d32b-4a6a-892f-ed69b21fc5fe', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '601638f8-2323-4dbb-98b1-3726b412c2f1', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-bf274fe1-edfd-4248-b785-109e9a3b02df-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'e0f61746-d32b-4a6a-892f-ed69b21fc5fe', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '47485b1c-3b5d-41e4-80c6-6cd5a4879253', 'tool_call_id': 'e0f61746-d32b-4a6a-892f-ed69b21fc5fe', 'artifact': None, 'status': 'success'}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '601638f8-2323-4dbb-98b1-3726b412c2f1', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-bf274fe1-edfd-4248-b785-109e9a3b02df-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'e0f61746-d32b-4a6a-892f-ed69b21fc5fe', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '47485b1c-3b5d-41e4-80c6-6cd5a4879253', 'tool_call_id': 'e0f61746-d32b-4a6a-892f-ed69b21fc5fe', 'artifact': None, 'status': 'success'}, {'content': 'The result is 6.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-6a698ef9-8e9e-44cc-b132-f905bb7c4c25-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 7, 'total_tokens': 208, 'input_token_details': {'cache_read': 0}}}]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import convert_to_messages\n",
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
        "    messages = event.data.get('messages',None)\n",
        "    if messages:\n",
        "        print(convert_to_messages(messages)[-1])\n",
        "    print('='*25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8lJ0_BbpuD0",
        "outputId": "026c1940-6afa-4429-ac41-dc7355386068"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================\n",
            "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} response_metadata={} id='96cbd80f-6c6e-4cf5-9b7a-39a0b437477e'\n",
            "=========================\n",
            "content='' additional_kwargs={'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}} response_metadata={} id='run-f96dfccd-84f9-419b-898e-65c7b654b29a-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '33c1bd96-2366-4e77-afa0-457e88d495cc', 'type': 'tool_call'}]\n",
            "=========================\n",
            "content='6' name='multiply' id='234a5ada-c9c1-4449-aa06-58f4dd92ad82' tool_call_id='33c1bd96-2366-4e77-afa0-457e88d495cc'\n",
            "=========================\n",
            "content='The result is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 7, 'total_tokens': 208, 'input_token_details': {'cache_read': 0}}} response_metadata={} id='run-3bd61735-1a31-4bf6-a2fe-3633985ae3d8-0'\n",
            "=========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],\n",
        "                                      assistant_id=\"agent\",\n",
        "                                      input={\"messages\": [input_message]},\n",
        "                                      stream_mode=\"messages\"):\n",
        "    print(event.event)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6XN3qmJpxKM",
        "outputId": "a9ff0bae-1a8f-4024-e2c2-ecec2fd2df3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadata\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/metadata\n",
            "messages/complete\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "\n",
        "def format_tool_calls(tool_calls):\n",
        "    \"\"\"\n",
        "    Format a list of tool calls into a readable string.\n",
        "\n",
        "    Args:\n",
        "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
        "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if tool_calls:\n",
        "        formatted_calls = []\n",
        "        for call in tool_calls:\n",
        "            formatted_calls.append(\n",
        "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
        "            )\n",
        "        return \"\\n\".join(formatted_calls)\n",
        "    return \"No tool calls\"\n",
        "\n",
        "async for event in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input={\"messages\": [input_message]},\n",
        "    stream_mode=\"messages\",):\n",
        "\n",
        "    # Handle metadata events\n",
        "    if event.event == \"metadata\":\n",
        "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Handle partial message events\n",
        "    elif event.event == \"messages/partial\":\n",
        "        for data_item in event.data:\n",
        "            # Process user messages\n",
        "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
        "                print(f\"Human: {data_item['content']}\")\n",
        "            else:\n",
        "                # Extract relevant data from the event\n",
        "                tool_calls = data_item.get(\"tool_calls\", [])\n",
        "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
        "                content = data_item.get(\"content\", \"\")\n",
        "                response_metadata = data_item.get(\"response_metadata\", {})\n",
        "\n",
        "                if content:\n",
        "                    print(f\"AI: {content}\")\n",
        "\n",
        "                if tool_calls:\n",
        "                    print(\"Tool Calls:\")\n",
        "                    print(format_tool_calls(tool_calls))\n",
        "\n",
        "                if invalid_tool_calls:\n",
        "                    print(\"Invalid Tool Calls:\")\n",
        "                    print(format_tool_calls(invalid_tool_calls))\n",
        "\n",
        "                if response_metadata:\n",
        "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
        "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
        "\n",
        "        print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfEQAO4ep13x",
        "outputId": "b1fde439-acdb-4418-9dcb-4abd64345b6b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata: Run ID - 1efcd8bd-f05b-61ad-b93e-55780f393cb9\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: 55c0bb10-ec1e-488c-a16f-2b5f4e92beac, Function: multiply, Arguments: {'a': 2.0, 'b': 3.0}\n",
            "Response Metadata: Finish Reason - N/A\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: 55c0bb10-ec1e-488c-a16f-2b5f4e92beac, Function: multiply, Arguments: {'a': 2.0, 'b': 3.0}\n",
            "Response Metadata: Finish Reason - STOP\n",
            "--------------------------------------------------\n",
            "AI: The\n",
            "Response Metadata: Finish Reason - N/A\n",
            "--------------------------------------------------\n",
            "AI: The result is 6.\n",
            "Response Metadata: Finish Reason - STOP\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}