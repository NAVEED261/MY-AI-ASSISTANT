{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAVEED261/MY-AI-ASSISTANT/blob/main/module_3__streaming_interruption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
      "metadata": {
        "id": "319adfec-2d0a-49f2-87f9-275c4a32add2"
      },
      "source": [
        "# Streaming\n",
        "\n",
        "## Review\n",
        "\n",
        "In module 2, covered a few ways to customize graph state and memory.\n",
        "\n",
        "We built up to a Chatbot with external memory that can sustain long-running conversations.\n",
        "\n",
        "## Goals\n",
        "\n",
        "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways.\n",
        "\n",
        "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
      "metadata": {
        "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa"
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_google_genai langgraph_sdk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
      "metadata": {
        "id": "70d7e41b-c6ba-4e47-b645-6c110bede549"
      },
      "source": [
        "## Streaming\n",
        "\n",
        "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
        "\n",
        "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b430d92-f595-4322-a56e-06de7485daa8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b430d92-f595-4322-a56e-06de7485daa8",
        "outputId": "52db72b3-6c0e-4e44-c0d0-23394b057059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_API_KEY=AIzaSyC_lrcvf9V12RCOlCiSUv9fQHlwkzxRoUw\n",
            "AIzaSyC_lrcvf9V12RCOlCiSUv9fQHlwkzxRoUw\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "%env GOOGLE_API_KEY = {userdata.get('GOOGLE_API_KEY')}\n",
        "\n",
        "import os\n",
        "print(os.environ[\"GOOGLE_API_KEY\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b2a5d0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b2a5d0a",
        "outputId": "36121ebe-68d3-4c76-c409-12de07eba8b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: LANGCHAIN_API_KEY={userdata.get('LANGCHAIN_API_KEY')}\n"
          ]
        }
      ],
      "source": [
        "%env LANGCHAIN_API_KEY = {userdata.get('LANGCHAIN_API_KEY')}\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d0682fc",
      "metadata": {
        "id": "4d0682fc"
      },
      "source": [
        "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
        "outputId": "84476bc6-4d14-4550-efad-985bbd243a70"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "# LLM\n",
        "model: ChatGoogleGenerativeAI = ChatGoogleGenerativeAI(model = \"gemini-1.5-flash\")\n",
        "\n",
        "# State\n",
        "class State(MessagesState):\n",
        "    summary: str\n",
        "\n",
        "# Define the logic to call the model\n",
        "def call_model(state: State, config: RunnableConfig):\n",
        "\n",
        "    # Get summary if it exists\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # If there is summary, then we add it\n",
        "    if summary:\n",
        "\n",
        "        # Add summary to system message\n",
        "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
        "\n",
        "        # Append summary to any newer messages\n",
        "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
        "\n",
        "    else:\n",
        "        messages = state[\"messages\"]\n",
        "\n",
        "    response = model.invoke(messages, config)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "def summarize_conversation(state: State):\n",
        "\n",
        "    # First, we get any existing summary\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # Create our summarization prompt\n",
        "    if summary:\n",
        "\n",
        "        # A summary already exists\n",
        "        summary_message = (\n",
        "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
        "            \"Extend the summary by taking into account the new messages above:\"\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        summary_message = \"Create a summary of the conversation above:\"\n",
        "\n",
        "    # Add prompt to our history\n",
        "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Delete all but the 2 most recent messages\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
        "\n",
        "# Determine whether to end or summarize the conversation\n",
        "def should_continue(state: State):\n",
        "\n",
        "    \"\"\"Return the next node to execute.\"\"\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # If there are more than six messages, then we summarize the conversation\n",
        "    if len(messages) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "\n",
        "    # Otherwise we can just end\n",
        "    return END\n",
        "\n",
        "# Define a new graph\n",
        "workflow: StateGraph = StateGraph(State)\n",
        "workflow.add_node(\"conversation\", call_model)\n",
        "workflow.add_node(summarize_conversation)\n",
        "\n",
        "# Set the entrypoint as conversation\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "# Compile\n",
        "memory: MemorySaver = MemorySaver()\n",
        "graph: CompiledStateGraph = workflow.compile(checkpointer=memory)\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f847a787-b301-488c-9b58-cba9f389f55d",
      "metadata": {
        "id": "f847a787-b301-488c-9b58-cba9f389f55d"
      },
      "source": [
        "### Streaming full state\n",
        "\n",
        "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
        "\n",
        "`.stream` and `.astream` are sync and async methods for streaming back results.\n",
        "\n",
        "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
        "\n",
        "* `values`: This streams the full state of the graph after each node is called.\n",
        "* `updates`: This streams updates to the state of the graph after each node is called.\n",
        "\n",
        "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
        "\n",
        "Let's look at `stream_mode=\"updates\"`.\n",
        "\n",
        "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
        "\n",
        "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
        "outputId": "2069bb28-efe5-49de-86e3-924ea5d033a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'conversation': {'messages': AIMessage(content='Hi Lance!  Nice to meet you.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d96ff0dd-e319-4feb-b8f9-15a50f558af7-0', usage_metadata={'input_tokens': 7, 'output_tokens': 10, 'total_tokens': 17, 'input_token_details': {'cache_read': 0}})}}\n"
          ]
        }
      ],
      "source": [
        "# Create a thread\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Start conversation\n",
        "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
        "    print(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
      "metadata": {
        "id": "0c4882e9-07dd-4d70-866b-dfc530418cad"
      },
      "source": [
        "Let's now just print the state update."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c859c777-cb12-4682-9108-6b367e597b81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c859c777-cb12-4682-9108-6b367e597b81",
        "outputId": "d72c09a4-fb5d-48e2-f645-fc1837e8172e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi Lance! It's nice to meet you (again!). How can I help you today?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        }
      ],
      "source": [
        "# Start conversation\n",
        "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
        "    chunk['conversation'][\"messages\"].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "583bf219-6358-4d06-ae99-c40f43569fda",
      "metadata": {
        "id": "583bf219-6358-4d06-ae99-c40f43569fda"
      },
      "source": [
        "Now, we can see `stream_mode=\"values\"`.\n",
        "\n",
        "This is the `full state` of the graph after the `conversation` node is called."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
        "outputId": "d78f2bda-36f1-464a-e409-cc159dea33bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hi! I'm Hafiz naveed uddin\n",
            "---------------------------------------------------------------------------\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "hi! I'm Hafiz naveed uddin\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hello Hafiz Naveed Uddin!  It's nice to meet you.  How can I help you today?\n",
            "---------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        }
      ],
      "source": [
        "# Start conversation, again\n",
        "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
        "\n",
        "# Start conversation\n",
        "input_message = HumanMessage(content=\"hi! I'm Hafiz naveed uddin\")\n",
        "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
        "    for m in event['messages']:\n",
        "        m.pretty_print()\n",
        "    print(\"---\"*25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
      "metadata": {
        "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7"
      },
      "source": [
        "### Streaming tokens\n",
        "\n",
        "We often want to stream more than graph state.\n",
        "\n",
        "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
        "\n",
        "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
        "\n",
        "Each event is a dict with a few keys:\n",
        "\n",
        "* `event`: This is the type of event that is being emitted.\n",
        "* `name`: This is the name of event.\n",
        "* `data`: This is the data associated with the event.\n",
        "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
        "\n",
        "Let's have a look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
        "outputId": "97a19e50-81b1-45e8-a369-7bc33a2215f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node: . Type: on_chain_start. Name: LangGraph\n",
            "Node: __start__. Type: on_chain_start. Name: __start__\n",
            "Node: __start__. Type: on_chain_start. Name: _write\n",
            "Node: __start__. Type: on_chain_end. Name: _write\n",
            "Node: __start__. Type: on_chain_start. Name: _write\n",
            "Node: __start__. Type: on_chain_end. Name: _write\n",
            "Node: __start__. Type: on_chain_stream. Name: __start__\n",
            "Node: __start__. Type: on_chain_end. Name: __start__\n",
            "Node: conversation. Type: on_chain_start. Name: conversation\n",
            "Node: conversation. Type: on_chat_model_start. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_stream. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chat_model_end. Name: ChatGoogleGenerativeAI\n",
            "Node: conversation. Type: on_chain_start. Name: _write\n",
            "Node: conversation. Type: on_chain_end. Name: _write\n",
            "Node: conversation. Type: on_chain_start. Name: should_continue\n",
            "Node: conversation. Type: on_chain_end. Name: should_continue\n",
            "Node: conversation. Type: on_chain_stream. Name: conversation\n",
            "Node: conversation. Type: on_chain_end. Name: conversation\n",
            "Node: . Type: on_chain_stream. Name: LangGraph\n",
            "Node: . Type: on_chain_end. Name: LangGraph\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
        "\n",
        "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
        "\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "\n",
        "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
      "metadata": {
        "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d"
      },
      "source": [
        "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
        "\n",
        "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
        "\n",
        "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
        "outputId": "427c805b-1431-4b3e-9e12-5bff2a404f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 11, 'output_tokens': 0, 'total_tokens': 11, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' San Francisco 49ers are a professional American football team based in Santa Clara', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=', California.  They are members of the National Football Conference (NFC) West', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=\" division of the National Football League (NFL).\\n\\nHere's a summary of key aspects of the team:\\n\\n* **History:**  Founded in 1\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content='946 as the original San Francisco 49ers (they were one of the original members of the All-America Football Conference before joining the NFL in', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=\" 1949), they boast a rich and storied history.  They've won five Super Bowls (XVI, XIX, XXIII, XXIV, and XXIX), and are considered one of the most successful franchises in NFL history.\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content='  Their success was particularly prominent in the 1980s under legendary head coach Bill Walsh and quarterback Joe Montana.\\n\\n* **Recent Performance:** In recent years, the 49ers have experienced a resurgence after a period of', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=\" rebuilding.  They've been highly competitive, making multiple playoff appearances and reaching Super Bowl LIV in 2020, where they lost to the Kansas City Chiefs.  They consistently rank among the NFL's top teams.\\n\\n* **Key Players (This is subject to change each season):**  The\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=\" 49ers' success hinges on a strong roster.  While specific star players fluctuate year to year, key positions usually include a strong running game, a solid defense, and a capable quarterback.  Recent years have seen standout performances from players in various positions.  Looking up the current roster on the official 4\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=\"9ers website will give you the most up-to-date information on key players.\\n\\n* **Coaching Staff:** The head coach significantly impacts the team's performance.  The current coaching staff plays a critical role in shaping the team's strategies and player development.  Again, checking the official website will provide\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=\" the most current information.\\n\\n* **Stadium:** Levi's Stadium, located in Santa Clara, California, is the team's home.  It's a modern, state-of-the-art facility.\\n\\n* **Fanbase:** The 49ers have a passionate and large fanbase, both\", additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content=' locally in the Bay Area and across the country.  Their history and consistent competitiveness contribute to their strong following.\\n\\n\\nTo get the most up-to-date information on the 49ers, including their current roster, coaching staff, and recent news, I recommend visiting the official San Francisco 49ers website', additional_kwargs={}, response_metadata={'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}})}\n",
            "{'chunk': AIMessageChunk(content='.\\n', additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'safety_ratings': []}, id='run-d94fbc7f-c0cf-4d7b-be03-66799f6cec50', usage_metadata={'input_tokens': 0, 'output_tokens': 515, 'total_tokens': 515, 'input_token_details': {'cache_read': 0}})}\n"
          ]
        }
      ],
      "source": [
        "node_to_stream = 'conversation'\n",
        "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
        "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # Get chat model tokens from a particular node\n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        print(event[\"data\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
      "metadata": {
        "id": "226e569a-76c3-43d8-8f89-3ae687efde1c"
      },
      "source": [
        "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
        "outputId": "5e723d11-9e33-4813-8fff-9073cb4b2728"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithError: Failed to POST https://api.smith.langchain.com/runs/multipart in LangSmith API. HTTPError('403 Client Error: Forbidden for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Forbidden\"}')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The| San Francisco 49ers are a professional American football team based in San Francisco|, California.  They are members of the National Football Conference (NFC) West| division in the National Football League (NFL).\n",
            "\n",
            "Here's a summary of key aspects of the team:\n",
            "\n",
            "* **History:** Founded in 19|46 as the \"San Francisco Forty-Niners\" (the name referencing the 1849 California Gold Rush), they're one of the| NFL's most storied franchises.  They've won five Super Bowl championships (XVI, XIX, XXIII, XXIV, and XXIX), and have a rich history of legendary players and coaches.\n",
            "\n",
            "* **Recent Performance:**  The| 49ers have experienced a resurgence in recent years, after a period of rebuilding. They've been consistent playoff contenders and have been to the Super Bowl recently (Super Bowl LIV).  Their success is largely attributed to strong coaching and| a talented roster.\n",
            "\n",
            "* **Current Status:** The 49ers are currently a competitive team aiming for another Super Bowl run. Their success hinges on the health of their key players and the continued development of their younger talent.  Their exact standing changes year to year, so checking current NFL standings is recommended for the| most up-to-date information.\n",
            "\n",
            "* **Notable Players (Past & Present):** The 49ers have a long list of Hall of Fame players, including Joe Montana, Jerry Rice, Steve Young, Ronnie Lott, and more recently, players like Patrick Willis, Frank Gore, and more. The current| roster boasts several star players, although the specific lineup changes frequently.\n",
            "\n",
            "* **Stadium:** Levi's Stadium, located in Santa Clara, California, is their home stadium.\n",
            "\n",
            "* **Coaching Staff:** The head coach and coaching staff play a critical role in the team's success.  Information about the current coaching| staff is best found on the official 49ers website or reputable sports news sources.\n",
            "\n",
            "* **Ownership:**  The team is currently owned by Denise DeBartolo York and Jed York.\n",
            "\n",
            "To get the most current information on the 49ers' roster, standings, news, and schedule, it'|s best to check reputable sports news websites (like ESPN, NFL.com, etc.) or the official San Francisco 49ers website.\n",
            "|"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
        "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
        "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
        "    # Get chat model tokens from a particular node\n",
        "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
        "        data = event[\"data\"]\n",
        "        print(data[\"chunk\"].content, end=\"|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
      "metadata": {
        "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db"
      },
      "source": [
        "### Streaming with LangGraph API\n",
        "\n",
        "--\n",
        "\n",
        "**⚠️ DISCLAIMER**\n",
        "\n",
        "*Running Studio currently requires a Mac. If you are not using a Mac, then skip this step.*\n",
        "\n",
        "*Also, if you are running this notebook in CoLab, then skip this step.*\n",
        "\n",
        "--\n",
        "\n",
        "The LangGraph API [has first class support for streaming](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#streaming).\n",
        "\n",
        "Let's load our `agent` in the Studio UI, which uses `module-3/studio/agent.py` set in `module-3/studio/langgraph.json`.\n",
        "\n",
        "The LangGraph API serves as the back-end for Studio.\n",
        "\n",
        "We can interact directly with the LangGraph API via the LangGraph SDK.\n",
        "\n",
        "We just need to get the URL for the local deployment from Studio.\n",
        "\n",
        "![Screenshot 2024-08-27 at 2.20.34 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf8943c3d4df239cbf0f_streaming2.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "079c2ad6",
      "metadata": {
        "id": "079c2ad6"
      },
      "outputs": [],
      "source": [
        "from langgraph_sdk import get_client\n",
        "\n",
        "# Replace this with the URL of your own deployed graph\n",
        "URL = \"https://5ab6-202-59-13-144.ngrok-free.app\"\n",
        "client = get_client(url=URL)\n",
        "\n",
        "# Search all hosted graphs\n",
        "assistants = await client.assistants.search()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
      "metadata": {
        "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32"
      },
      "source": [
        "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
      "metadata": {
        "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
        "outputId": "33c6f931-66e2-4c53-a850-e3d3966d8708",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StreamPart(event='metadata', data={'run_id': '1efb7987-b8d8-676c-bc92-60c0c7e86b5b', 'attempt': 1})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2e7aec15-ded5-4846-97d9-7c3aa98ac328', 'example': False}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2e7aec15-ded5-4846-97d9-7c3aa98ac328', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-b456dc06-00ca-4e8d-b2cd-0fdc7b9445ab-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'b6187b68-9143-4775-bfd4-4b9ca6a317b9', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2e7aec15-ded5-4846-97d9-7c3aa98ac328', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-b456dc06-00ca-4e8d-b2cd-0fdc7b9445ab-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'b6187b68-9143-4775-bfd4-4b9ca6a317b9', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '453f39a5-62b7-4afe-bf5d-699eb9deea7f', 'tool_call_id': 'b6187b68-9143-4775-bfd4-4b9ca6a317b9', 'artifact': None, 'status': 'success'}]})\n",
            "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2e7aec15-ded5-4846-97d9-7c3aa98ac328', 'example': False}, {'content': '', 'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-b456dc06-00ca-4e8d-b2cd-0fdc7b9445ab-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': 'b6187b68-9143-4775-bfd4-4b9ca6a317b9', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '453f39a5-62b7-4afe-bf5d-699eb9deea7f', 'tool_call_id': 'b6187b68-9143-4775-bfd4-4b9ca6a317b9', 'artifact': None, 'status': 'success'}, {'content': 'The result is 6.\\n', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-50e79d99-7f82-4c11-a10a-f3bd0a788b00-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 7, 'total_tokens': 208, 'input_token_details': {'cache_read': 0}}}]})\n"
          ]
        }
      ],
      "source": [
        "# Create a new thread\n",
        "thread = await client.threads.create()\n",
        "# Input message\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],\n",
        "                                      assistant_id=\"agent\",\n",
        "                                      input={\"messages\": [input_message]},\n",
        "                                      stream_mode=\"values\"):\n",
        "    print(event)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
      "metadata": {
        "id": "556dc7fd-1cae-404f-816a-f13d772b3b14"
      },
      "source": [
        "The streamed objects have:\n",
        "\n",
        "* `event`: Type\n",
        "* `data`: State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b735aa-139c-45a3-a850-63519c0004f0",
      "metadata": {
        "id": "57b735aa-139c-45a3-a850-63519c0004f0",
        "outputId": "b72003d7-631c-42fc-c258-82a13b319478",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========================\n",
            "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} response_metadata={} id='f0bb24d4-80f4-4935-b0c5-9f6df1f54b20'\n",
            "=========================\n",
            "content='' additional_kwargs={'additional_kwargs': {'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 3.0}'}}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 168, 'output_tokens': 3, 'total_tokens': 171, 'input_token_details': {'cache_read': 0}}} response_metadata={} id='run-e1e70dd3-6979-4fd3-88ba-a3a21b5de385-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2.0, 'b': 3.0}, 'id': '4693bb9e-19fe-4d44-a2e1-abd1fdbba8b1', 'type': 'tool_call'}]\n",
            "=========================\n",
            "content='6' name='multiply' id='a0d5fe06-ff69-4b4b-9f1a-24d486dfb9ae' tool_call_id='4693bb9e-19fe-4d44-a2e1-abd1fdbba8b1'\n",
            "=========================\n",
            "content='The result is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 201, 'output_tokens': 6, 'total_tokens': 207, 'input_token_details': {'cache_read': 0}}} response_metadata={} id='run-99879e77-15fb-4574-bd76-80b0eb210771-0'\n",
            "=========================\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import convert_to_messages\n",
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
        "    messages = event.data.get('messages',None)\n",
        "    if messages:\n",
        "        print(convert_to_messages(messages)[-1])\n",
        "    print('='*25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a555d186-27be-4ddf-934c-895a3105035d",
      "metadata": {
        "id": "a555d186-27be-4ddf-934c-895a3105035d"
      },
      "source": [
        "There are some new streaming mode that are only supported via the API.\n",
        "\n",
        "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
        "\n",
        "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
        "\n",
        "All events emitted using `messages` mode have two attributes:\n",
        "\n",
        "* `event`: This is the name of the event\n",
        "* `data`: This is data associated with the event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
      "metadata": {
        "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
        "outputId": "34664544-d20b-4905-fc08-d067d6364420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metadata\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n",
            "messages/metadata\n",
            "messages/complete\n",
            "messages/metadata\n",
            "messages/partial\n",
            "messages/partial\n"
          ]
        }
      ],
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "async for event in client.runs.stream(thread[\"thread_id\"],\n",
        "                                      assistant_id=\"agent\",\n",
        "                                      input={\"messages\": [input_message]},\n",
        "                                      stream_mode=\"messages\"):\n",
        "    print(event.event)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
      "metadata": {
        "id": "8de2f1ea-b232-43fc-af7a-320efce83381"
      },
      "source": [
        "We can see a few events:\n",
        "\n",
        "* `metadata`: metadata about the run\n",
        "* `messages/complete`: fully formed message\n",
        "* `messages/partial`: chat model tokens\n",
        "\n",
        "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
        "\n",
        "Now, let's show how to stream these messages.\n",
        "\n",
        "We'll define a helper function for better formatting of the tool calls in messages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
      "metadata": {
        "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
        "outputId": "7fed815c-615f-4c22-8078-88b0d7807b5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metadata: Run ID - 1efb798d-e3e5-6515-b75e-ab48358b0c47\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: 4504d8e7-4ee0-4177-88c4-ed2a4bf5764c, Function: multiply, Arguments: {'a': 2.0, 'b': 3.0}\n",
            "Response Metadata: Finish Reason - N/A\n",
            "--------------------------------------------------\n",
            "Tool Calls:\n",
            "Tool Call ID: 4504d8e7-4ee0-4177-88c4-ed2a4bf5764c, Function: multiply, Arguments: {'a': 2.0, 'b': 3.0}\n",
            "Response Metadata: Finish Reason - STOP\n",
            "--------------------------------------------------\n",
            "AI: The\n",
            "Response Metadata: Finish Reason - N/A\n",
            "--------------------------------------------------\n",
            "AI: The result is 6.\n",
            "\n",
            "Response Metadata: Finish Reason - STOP\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "thread = await client.threads.create()\n",
        "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
        "\n",
        "def format_tool_calls(tool_calls):\n",
        "    \"\"\"\n",
        "    Format a list of tool calls into a readable string.\n",
        "\n",
        "    Args:\n",
        "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
        "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if tool_calls:\n",
        "        formatted_calls = []\n",
        "        for call in tool_calls:\n",
        "            formatted_calls.append(\n",
        "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
        "            )\n",
        "        return \"\\n\".join(formatted_calls)\n",
        "    return \"No tool calls\"\n",
        "\n",
        "async for event in client.runs.stream(\n",
        "    thread[\"thread_id\"],\n",
        "    assistant_id=\"agent\",\n",
        "    input={\"messages\": [input_message]},\n",
        "    stream_mode=\"messages\",):\n",
        "\n",
        "    # Handle metadata events\n",
        "    if event.event == \"metadata\":\n",
        "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Handle partial message events\n",
        "    elif event.event == \"messages/partial\":\n",
        "        for data_item in event.data:\n",
        "            # Process user messages\n",
        "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
        "                print(f\"Human: {data_item['content']}\")\n",
        "            else:\n",
        "                # Extract relevant data from the event\n",
        "                tool_calls = data_item.get(\"tool_calls\", [])\n",
        "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
        "                content = data_item.get(\"content\", \"\")\n",
        "                response_metadata = data_item.get(\"response_metadata\", {})\n",
        "\n",
        "                if content:\n",
        "                    print(f\"AI: {content}\")\n",
        "\n",
        "                if tool_calls:\n",
        "                    print(\"Tool Calls:\")\n",
        "                    print(format_tool_calls(tool_calls))\n",
        "\n",
        "                if invalid_tool_calls:\n",
        "                    print(\"Invalid Tool Calls:\")\n",
        "                    print(format_tool_calls(invalid_tool_calls))\n",
        "\n",
        "                if response_metadata:\n",
        "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
        "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
        "\n",
        "        print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
      "metadata": {
        "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}